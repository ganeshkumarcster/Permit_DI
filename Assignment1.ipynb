{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook created for Coursera capstone project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\admin\\\\Desktop\\\\Caps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\Desktop\\\\Caps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_project = pd.read_csv('projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_project['date_posted'] = pd.to_datetime(data_project['date_posted'], format= '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619326"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_project.loc[data_project['date_posted'] < pd.Timestamp(2014,1,1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_outcome has records or Projects submitted before 2014-01-01 - It is consider as Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outcome = pd.read_csv('outcomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_essay = pd.read_csv('essays.csv',nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sample Audit data Report - Projects.csv Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmiss=pd.DataFrame((data_project.isnull().sum()/len(data_project.isnull()))*100,columns=['Miss Perc'])\n",
    "dmiss['Miss']=data_project.isnull().sum()\n",
    "summary_project=data_project.describe(percentiles=[0.05,0.10,0.25,0.50,0.75,0.85,0.95,0.99])\n",
    "summary_project=summary_project.T\n",
    "newsummary=pd.concat([dmiss,summary_project],axis=1)\n",
    "newsummary.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsummary.to_csv('sample_audit_project.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sample Audit data Report - Essays Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emiss=pd.DataFrame((data_essay.isnull().sum()/len(data_essay.isnull()))*100,columns=['Miss Perc'])\n",
    "emiss['Miss']=data_essay.isnull().sum()\n",
    "summary_essay=data_essay.describe(percentiles=[0.05,0.10,0.25,0.50,0.75,0.85,0.95,0.99])\n",
    "summary_essay=summary_essay.T\n",
    "newsummary1=pd.concat([emiss,summary_essay],axis=1)\n",
    "newsummary1.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsummary.to_csv('sample_audit_essay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_zip</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>...</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>fulfillment_labor_materials</th>\n",
       "      <th>total_price_excluding_optional_support</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>eligible_almost_home_match</th>\n",
       "      <th>date_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316ed8fb3b81402ff6ac8f721bb31192</td>\n",
       "      <td>42d43fa6f37314365d08692e08680973</td>\n",
       "      <td>c0e6ce89b244764085691a1b8e28cb81</td>\n",
       "      <td>6.362701e+10</td>\n",
       "      <td>36.576340</td>\n",
       "      <td>-119.608713</td>\n",
       "      <td>Selma</td>\n",
       "      <td>CA</td>\n",
       "      <td>93662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>555.81</td>\n",
       "      <td>653.89</td>\n",
       "      <td>32.0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2014-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90de744e368a7e4883223ca49318ae30</td>\n",
       "      <td>864eb466462bf704bf7a16a585ef296a</td>\n",
       "      <td>d711e47810900c96f26a5d0be30c446d</td>\n",
       "      <td>4.837020e+11</td>\n",
       "      <td>32.911179</td>\n",
       "      <td>-96.723640</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>75243</td>\n",
       "      <td>urban</td>\n",
       "      <td>...</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>296.47</td>\n",
       "      <td>348.79</td>\n",
       "      <td>22.0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2014-05-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  316ed8fb3b81402ff6ac8f721bb31192  42d43fa6f37314365d08692e08680973   \n",
       "1  90de744e368a7e4883223ca49318ae30  864eb466462bf704bf7a16a585ef296a   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  c0e6ce89b244764085691a1b8e28cb81   6.362701e+10        36.576340   \n",
       "1  d711e47810900c96f26a5d0be30c446d   4.837020e+11        32.911179   \n",
       "\n",
       "   school_longitude school_city school_state  school_zip school_metro  ...  \\\n",
       "0       -119.608713       Selma           CA       93662          NaN  ...   \n",
       "1        -96.723640      Dallas           TX       75243        urban  ...   \n",
       "\n",
       "  resource_type    poverty_level    grade_level fulfillment_labor_materials  \\\n",
       "0         Books  highest poverty     Grades 6-8                        30.0   \n",
       "1         Books  highest poverty  Grades PreK-2                        30.0   \n",
       "\n",
       "  total_price_excluding_optional_support  \\\n",
       "0                                 555.81   \n",
       "1                                 296.47   \n",
       "\n",
       "  total_price_including_optional_support students_reached  \\\n",
       "0                                 653.89             32.0   \n",
       "1                                 348.79             22.0   \n",
       "\n",
       "  eligible_double_your_impact_match eligible_almost_home_match date_posted  \n",
       "0                                 f                          f  2014-05-12  \n",
       "1                                 f                          f  2014-05-12  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_project.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>is_exciting</th>\n",
       "      <th>at_least_1_teacher_referred_donor</th>\n",
       "      <th>fully_funded</th>\n",
       "      <th>at_least_1_green_donation</th>\n",
       "      <th>great_chat</th>\n",
       "      <th>three_or_more_non_teacher_referred_donors</th>\n",
       "      <th>one_non_teacher_referred_donor_giving_100_plus</th>\n",
       "      <th>donation_from_thoughtful_donor</th>\n",
       "      <th>great_messages_proportion</th>\n",
       "      <th>teacher_referred_count</th>\n",
       "      <th>non_teacher_referred_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffffc4f85b60efc5b52347df489d0238</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ffffac55ee02a49d1abc87ba6fc61135</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ffff97ed93720407d70a2787475932b0</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid is_exciting  \\\n",
       "0  ffffc4f85b60efc5b52347df489d0238           f   \n",
       "1  ffffac55ee02a49d1abc87ba6fc61135           f   \n",
       "2  ffff97ed93720407d70a2787475932b0           f   \n",
       "\n",
       "  at_least_1_teacher_referred_donor fully_funded at_least_1_green_donation  \\\n",
       "0                               NaN            f                       NaN   \n",
       "1                                 f            t                         t   \n",
       "2                                 f            t                         t   \n",
       "\n",
       "  great_chat three_or_more_non_teacher_referred_donors  \\\n",
       "0          f                                       NaN   \n",
       "1          f                                         t   \n",
       "2          t                                         t   \n",
       "\n",
       "  one_non_teacher_referred_donor_giving_100_plus  \\\n",
       "0                                            NaN   \n",
       "1                                              f   \n",
       "2                                              t   \n",
       "\n",
       "  donation_from_thoughtful_donor  great_messages_proportion  \\\n",
       "0                            NaN                        NaN   \n",
       "1                              f                       57.0   \n",
       "2                              f                      100.0   \n",
       "\n",
       "   teacher_referred_count  non_teacher_referred_count  \n",
       "0                     NaN                         NaN  \n",
       "1                     0.0                         7.0  \n",
       "2                     0.0                         3.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_outcome.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merge Project and Essay dataset by using key ProjectID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= pd.merge(data_project,data_essay,on='projectid',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6670"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.loc[data1['date_posted'] >= pd.Timestamp(2014,1,1)]['date_posted'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate the TEST_data_set by extract Project submitted after 2014-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=data1[data1['date_posted'] >= pd.Timestamp(2014,1,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Generate the TRAIN_data_set by extract Project submitted before 2014-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datb=data1[data1['date_posted'] < pd.Timestamp(2014,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_project['projectid'] = data_project['projectid'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outcome['projectid'] = data_outcome['projectid'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.merge(data_project,data_outcome,on='projectid',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outcome.csv has only projects prior to 2014-1-1 i.e) train records.\n",
    "data_train[data_train['date_posted'] > pd.Timestamp(2014,1,1)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat=data_train[data_train['date_posted'] <= pd.Timestamp(2014,1,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature selections and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll_train= pd.merge(train_datb,train_dat[['projectid','is_exciting']],on='projectid',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93330, 41)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAll_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['projectid', 'teacher_acctid_x', 'schoolid', 'school_ncesid',\n",
       "       'school_latitude', 'school_longitude', 'school_city', 'school_state',\n",
       "       'school_zip', 'school_metro', 'school_district', 'school_county',\n",
       "       'school_charter', 'school_magnet', 'school_year_round', 'school_nlns',\n",
       "       'school_kipp', 'school_charter_ready_promise', 'teacher_prefix',\n",
       "       'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
       "       'primary_focus_subject', 'primary_focus_area',\n",
       "       'secondary_focus_subject', 'secondary_focus_area', 'resource_type',\n",
       "       'poverty_level', 'grade_level', 'fulfillment_labor_materials',\n",
       "       'total_price_excluding_optional_support',\n",
       "       'total_price_including_optional_support', 'students_reached',\n",
       "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
       "       'date_posted', 'teacher_acctid_y', 'title', 'short_description',\n",
       "       'need_statement', 'essay', 'is_exciting'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAll_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Literacy & Language    42123\n",
       "Math & Science         22670\n",
       "Music & The Arts        8472\n",
       "Applied Learning        7124\n",
       "Special Needs           5882\n",
       "History & Civics        4531\n",
       "Health & Sports         2524\n",
       "Name: primary_focus_area, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAll_train['primary_focus_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_tovalue(x):\n",
    "    if x == 'Literacy & Language':\n",
    "        return 6\n",
    "    elif x == 'Math & Science':\n",
    "        return 5\n",
    "    elif x == 'Applied Learning':\n",
    "        return 4\n",
    "    elif x == 'Special Needs':\n",
    "        return 3\n",
    "    elif x == 'History & Civics':\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll_train['primary_focus_area']=dataAll_train['primary_focus_area'].apply(area_tovalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_data['primary_focus_area']=test_data['primary_focus_area'].apply(area_tovalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    42123\n",
       "5    22670\n",
       "1    11000\n",
       "4     7124\n",
       "3     5882\n",
       "2     4531\n",
       "Name: primary_focus_area, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAll_train['primary_focus_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plevel_tovalue(x):\n",
    "    if x == 'highest poverty':\n",
    "        return 5\n",
    "    elif x == 'high poverty':\n",
    "        return 4\n",
    "    elif x == 'moderate poverty':\n",
    "        return 3\n",
    "    elif x == 'low poverty':\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest poverty     53947\n",
       "high poverty        24477\n",
       "moderate poverty    12597\n",
       "low poverty          2309\n",
       "Name: poverty_level, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAll_train['poverty_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll_train['poverty_level'] = dataAll_train['poverty_level'].apply(plevel_tovalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_data['poverty_level'] =test_data['poverty_level'].apply(plevel_tovalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93311"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAll_train['students_reached'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract Train dataset with predictors i'e) X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_trainX = dataAll_train[['projectid','primary_focus_area','poverty_level','essay','is_exciting']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Extract Test dataset with X features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_testX = test_data[['projectid','primary_focus_area','poverty_level','essay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid             0\n",
       "primary_focus_area    0\n",
       "poverty_level         0\n",
       "essay                 0\n",
       "is_exciting           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null and data type\n",
    "d_trainX.isnull().sum()\n",
    "#d_trainX.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid             0\n",
       "primary_focus_area    0\n",
       "poverty_level         0\n",
       "essay                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_testX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    87751\n",
       "t     5579\n",
       "Name: is_exciting, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_trainX['is_exciting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objtostr(x):\n",
    "    if x == 'f':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "d_trainX['is_exciting'] = d_trainX['is_exciting'].apply(objtostr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid             object\n",
       "primary_focus_area     int64\n",
       "poverty_level          int64\n",
       "essay                 object\n",
       "is_exciting            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_trainX.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_dt = d_trainX['essay']\n",
    "essaydt_lst =essay_dt.tolist() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_x = d_testX['essay']\n",
    "essaydt_x =essay_x.tolist() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#By Using TfidfVectorizer convert Text into word matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "tf=text.TfidfVectorizer(essaydt_lst,stop_words='english',max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del matrix_tfidf_tst,d2,d1,X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_tfidf=tf.fit_transform(essaydt_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_tfidf_tst=tf.fit_transform(essaydt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93330, 1000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = pd.DataFrame(matrix_tfidf.toarray(),columns=tf.get_feature_names())\n",
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6670, 1000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_tst = pd.DataFrame(matrix_tfidf_tst.toarray(),columns=tf.get_feature_names())\n",
    "d2_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10         0\n",
      "100        0\n",
      "12         0\n",
      "15         0\n",
      "1st        0\n",
      "          ..\n",
      "writing    0\n",
      "written    0\n",
      "year       0\n",
      "years      0\n",
      "young      0\n",
      "Length: 1000, dtype: int64\n",
      "10         0\n",
      "100        0\n",
      "12         0\n",
      "15         0\n",
      "1st        0\n",
      "          ..\n",
      "writing    0\n",
      "written    0\n",
      "year       0\n",
      "years      0\n",
      "young      0\n",
      "Length: 1000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(d2.isnull().sum())\n",
    "print(d2_tst.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del d1\n",
    "d1=d_trainX[['primary_focus_area','poverty_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1tst=d_testX[['primary_focus_area','poverty_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([d2,d1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.concat([d2_tst,d1tst],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['10', '100', '12', '15', '1st', '20', '21st', '24', '25', '2nd',\n",
      "       ...\n",
      "       'world', 'write', 'writers', 'writing', 'written', 'year', 'years',\n",
      "       'young', 'primary_focus_area', 'poverty_level'],\n",
      "      dtype='object', length=1002)\n"
     ]
    }
   ],
   "source": [
    "d_trainX.shape\n",
    "#print(trainAll.shape)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['10', '100', '12', '15', '1st', '20', '21st', '24', '25', '2nd',\n",
      "       ...\n",
      "       'world', 'write', 'writers', 'writing', 'written', 'year', 'years',\n",
      "       'young', 'primary_focus_area', 'poverty_level'],\n",
      "      dtype='object', length=1002)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del y\n",
    "y=d_trainX['is_exciting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "trainX,testX,trainY,testY=model_selection.train_test_split(X,y,test_size=0.2,random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "clf=linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "mod=clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6746836483574834"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the roc score \n",
    "import sklearn.metrics as metrics\n",
    "predicted=mod.predict_proba(testX)\n",
    "metrics.roc_auc_score(testY,predicted[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train the model by using only 0.8 percent of Train Data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "modTtrain=clf.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6746836483574834"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the roc score \n",
    "import sklearn.metrics as metrics\n",
    "predicted_test=modTtrain.predict_proba(testX)\n",
    "metrics.roc_auc_score(testY,predicted_test[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Regularize the model by using Gridsearch with  5 fold CV & l2 penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(300)\n",
    "modReg=model_selection.GridSearchCV(clf,param_grid={'penalty':['l2'],'C':np.random.uniform(0,40,2)},cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "grd_cv=modReg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=18.04490274800219, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.9397835636987034\n"
     ]
    }
   ],
   "source": [
    "print(grd_cv.best_estimator_)\n",
    "print(grd_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279469309397625"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd_predicted_test=grd_cv.predict_proba(testX)\n",
    "metrics.roc_auc_score(testY,grd_predicted_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_penalty', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd_cv.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(results,n=2):\n",
    "    lst=[]\n",
    "    for i in range(0,n):\n",
    "        n = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for j in n:\n",
    "            lst.append(results['split0_test_score'][j])\n",
    "            lst.append(results['split1_test_score'][j])\n",
    "            lst.append(results['split2_test_score'][j])\n",
    "            lst.append(results['split3_test_score'][j])\n",
    "            lst.append(results['split4_test_score'][j])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fold, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=res(grd_cv.cv_results_,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9383906568091718,\n",
       " 0.9398907103825137,\n",
       " 0.940158577092039,\n",
       " 0.9402657237758492,\n",
       " 0.940212150433944]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score=pd.DataFrame({'Fold':np.arange(0,5),'Auc':res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score.to_csv('AucReport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test=grd_cv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "did=test_data['projectid']\n",
    "result=pd.DataFrame(list(zip(predicted_test[:,1],did)),columns=[\"is_exciting\",\"projectId\"])\n",
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using NMF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition as decomposition\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmf=decomposition.PCA(100)\n",
    "nmf=decomposition.NMF(n_components=100)\n",
    "#scalers=preprocessing.StandardScaler()\n",
    "#X1=scalers.fit_transform(matrix_tfidf)\n",
    "#pca.fit_transform(X1)\n",
    "matrix_reduced_nmf=nmf.fit_transform(matrix_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139972, 100)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_reduced_nmf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = pd.DataFrame(matrix_reduced_nmf.tolist())\n",
    "X1=pd.concat([d3,d1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train,X1_test,y1_train,y1_test=model_selection.train_test_split(X1,y,test_size=0.2,random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=linear_model.LogisticRegression()\n",
    "nmfmod=clf.fit(X1_train,y1_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5966952401469932"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y1_test,nmfmod.predict_proba(X1_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
